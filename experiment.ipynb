{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1.04M/1.04M [00:01<00:00, 675kB/s] \n",
      "Downloading: 100%|██████████| 456k/456k [00:01<00:00, 232kB/s]  \n",
      "Downloading: 100%|██████████| 665/665 [00:00<00:00, 273kB/s]\n",
      "Downloading: 100%|██████████| 548M/548M [00:14<00:00, 39.0MB/s] \n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2Model.from_pretrained('gpt2')\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x 23', 'x 127']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Action a Reward 23 Action b Reward 127\"\n",
    "reward_tokens = ['a 23', 'a 127']\n",
    "# for i in range(len(reward_tokens)):\n",
    "#     r = reward_tokens[i]\n",
    "#     reward_tokens.append(r+\" \")\n",
    "#     reward_tokens.append(\" \"+r)\n",
    "#     reward_tokens.append(\" \"+r+\" \")\n",
    "reward_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[12502,   257, 32307,  2242,  7561,   275, 32307, 18112]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2242, 18112]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_rewards = [tokenizer.encode(reward_tokens[i])[1] for i in range(len(reward_tokens))]\n",
    "encoded_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2242  23\n",
      "18112  127\n"
     ]
    }
   ],
   "source": [
    "for token in encoded_rewards:\n",
    "    print(token, tokenizer.decode(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12502) Action\n",
      "tensor(257)  a\n",
      "tensor(32307)  Reward\n",
      "tensor(2242)  23\n",
      "tensor(7561)  Action\n",
      "tensor(275)  b\n",
      "tensor(32307)  Reward\n",
      "tensor(18112)  127\n"
     ]
    }
   ],
   "source": [
    "for el in encoded_input['input_ids'][0]:\n",
    "    print(el, tokenizer.decode(el))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = encoded_input['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-100, -100, -100, tensor(2242), -100, -100, -100, tensor(18112)]]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [[l if l in encoded_rewards else -100 for l in inp] for inp in input_ids]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124439808"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c821b3ac4508363ab26790ea772768a10c1768efd11bb9891ab119aba586fc55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
